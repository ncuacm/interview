### 物理层

### 数据链路层

+ 这一层主要的是可以进行差错检测和选择重传。

### 网络层

+ 这一层主要的协议是IP协议。
+ 网络层的主要任务是将从运输层所传下来的分组，通过网络层中的网络找到相应的主机。互联网的异构网络是由许多路由器组成，同时网络层的协议是由无连接的网际协议和路由选择协议组成。
+ ARP协议，这是属于网络层的协议，主要的作用就是将ip转化为mac地址，在每个主机或者路由器上都建有一个ARP缓存，表中有IP地址和IP地址对应的MAC地址。在同一个局域网上面的请求，不同的主机之间可以通过广播的方式来寻找目的地址，如果在不同的局域网里面，就需要先通过广播找到该局域网上面的路由器，然后通过路由器找到目的地址。在寻找目的地址的过程中，源ip和目的ip都是不变的，变的是选找的mac地址。
+ ping的过程
  + ping的过程主要涉及的协议是ICMP报文，主要是用来测试两个不同的主机之间的联通性的。
  + ping是向目的主机发送icmp回送报文。根据目的主机回送报文的往返时间和成功响应的次数来估测往返时间和丢包率。

### 运输层

+ 运输层主要有两种协议，TCP和UDP，分别是传输控制协议和用户数据协议。

+ TCP
  + TCP是面向有连接的，通信的方式是点对点的，提供可靠的交付，全双工通信，传输的是字节流。
  
+ UDP
  + UDP是面向报文的，不保证可靠的交付，尽最大努力完成交付。没有拥塞控制，因此不会出现网络拥堵造成的通信质量的下降，多用于实时通信领域。支持一对一，一对多，多对多的通信。

+ 三次握手和四次挥手

  - **什么是TCP**
    - TCP是一种面向连接的单播协议，在发送数据之前，通信双方需要在彼此之间建立一条连接。所谓的连接，其实就是客户端和服务端的内存里保存的一份关于对方的信息，比如IP地址，端口号等等
    - TCP可以看作是一种字节流，它会处理IP层或以下的层的丢包，重复和错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放到TCP头部
    - TCP提供一种可靠，面向连接，字节流，传输层的服务，采用三次握手来建立一个连接，四次挥手来释放一个连接。
    - 一个TCP连接分为三个阶段，启动，数据传输和退出。
  
  - **TCP头部**
    - 源端口和目的端口在TCP层确认双方进程，序列号表示的是报文段数据中的第一次字节号，ACK是确认号，该确认号的发送方期待接收的下一个序列号，即最后被成功接收的数据字节序列号加1,只有在ACK位启用的时候才有效。
    - 几个状态号的含义：ACK-确认，使得确认号有效，RST-重置连接，SYB-用于初始化一个连接的序列号，FIN-该报文段的发送方已经结束向对方发送数据

  - **状态转换如下图**
  
  ![img](https://cdn.nlark.com/yuque/0/2021/png/2752815/1637493992028-6ec9e9cf-07c8-4720-aeb7-c02a4bed23a3.png)
  
  - **三次握手**
  
    - 第一次握手，客户端发送网络包，服务端收到了，这样服务端就得出结论，客户端的发送能力和服务端的接收能力都是正常的。
  
    - 第二次握手，服务端发送包，客户端收到了，这样客户端就可以得到结论，服务端和客户端的发送能力和客户端的接收能力都是正常的。这样客户端就知道了自己的发送能力和接受能力都是正常的。**所以第二次握手的时候客户端就可以确定服务端和客户端是否可以正常通信。**
    - 第三次握手，客户端发送数据包，服务端收到了。在第一二次握手的阶段，**服务端不知道客户端的接收能力和自己的发送能力是否正常**。但是在第三次握手的时候，服务端收到了客户端对自己的第二次握手的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接受到了，所以，我的发送能力是正常的，客户端的接受能力是正常的。
  - 通过了以上三次握手，客户端和服务端就都知道了对方和自己的发送能力和接受能力都是正常的。接下来就是正常的通信了。
  - **更加专业化的语言描述三次握手**
    - 客户端发送一个SYN段，并指明客户端的初始序列号，即ISN(c)
    - 服务端发送自己的SYN段作为应答，同时指明自己的ISN(s).为了确认客户端的SYN，将ISN(c)+1作为ACK的值，这样，每次发送一个SYN，序列号就会加1,如果有丢失的情况，就会重传
    - 为了确认服务器的SYN，客户端需要将SYN(s)+1作为返回的ACK的值

- **四次挥手**
  - 当客户端和服务端的一方想要关闭连接的时候，会发送指令告知对方（一次），我要关闭连接了。这个时候对方会返回一个ACK，表示同意你这个方向的连接（两次）。**然后此时一个方向的连接已经关闭了**。但是可能对方正在传输数据，所以需要等到所有的数据都传输完毕之后，对方发送一个FIN来关闭此方向的连接（三次），接受方接收到后发送一个ACK来确认关闭连接（四次）。
  - **更加专业化的语言描述四次挥手**
    - 户端发送一个FIN段，并包含一个希望接收者看到的自己当前的序列号K，同时还包含一个ACK表示确认对方最近一次发过来的数据
    - 服务端将K值加1作为ACK序列值，表明收到一个包，这时上层的程序将会被告知另一端发起了关闭操作。
    - 服务端发送一个FIN段，ACK=K+1，Seq=L
    - 客户端发送确认，ACK=L+1
- **为什么建立连接是三次握手，断开连接确是四次挥手？**
  - - 这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文段后，**把ACK和SYN放到一个报文里面发送给客户端**;关闭连接时，当收到对方的FIN报文段的时候，仅仅表示对方不再发送数据了，但是对方还是可以接收数据，己方是否现在关闭数据通道，需要由上层决定。因此，**己方的ACK和FIN通常是分开的。**
- 在四次挥手中，为什么客户端进入TIME_WAIT之后需要等待2&MSL时间，而不是直接进入CLOSE状态？
  - 客户端在给服务端回执的时候，可能服务端没有收到，那么需要再次向客户端发送FIN=1的断开请求报文。此时，如果客户端立马关闭，那么服务端就会因为没有收到报文而无法进入CLOSE状态。
  - 等待一段时间是为了让进入本次连接的所有报文段的信息都消失，不会对下次的连接的报文段产生影响。
- TCP的拥塞控制
  + 拥塞控制分为四个步骤，分别是慢启动，拥塞避免，快重传，快恢复。
  + 慢启动，我们设置一个拥塞窗口，如果立刻把大量的数据字节注入信道里面，很有可能会造成网络拥堵。那么我们就慢慢增大这个拥塞窗口。在每次收到一个对新的报文的确认之后，我们将窗口增大一些。
  + 拥塞避免。当我们进行慢启动的时候，但是拥有塞窗口增长过大也可能导致网络拥堵，所以我们需要设置一个慢开始门限。如果我们的拥塞窗口小于这个门限，那么我们可以使用慢启动算法。否则我们可以使用拥塞避免算法。拥塞避免算法就是将我们的拥塞窗口缓慢增大，在收到一次确认的报文段之后，我们只要将这个窗口缓慢增大。
  + 快重传，当我们的数据丢失之后，我们需要让发送方尽早知道发生了个别报文的丢失。这样就要求发送方不要等待自己发送数据的时候顺带确认，而是直接发送确认。如果发送方连收到了三个确认，那么说明这个报文段需要重传。
  + 快恢复。就是发送方知道了只是丢失了几个报文段。于是不启动慢开始，而是执行快恢复算法。设置好门限和拥塞窗口。并开始执行拥塞避免算法。
- 为什么需要三次握手？
  + 对于请求的建立，假如发送端发送了某一个请求，但是网络拥堵没有在规定的时间内到达，那么就会隔很长的时间爱你才能收到服务端发回的确认连接。客户端等待一个超时重传的时间之后会重新请求连接。但是这个滞留的连接请求还是会到达服务器服务端。如果不进行三次握手，那么服务器就会打开两个连接，如果有第三次握手的机会，客户端就会忽略服务端之后发送的对滞留连接请求的连接确认。
- 为什么需要四次挥手？
  + 客户端收到了释放连接的请求之后，会发送一个一个FIN给服务端，然后进入TIME_WAIT时间段内，有这个时间段是为了让服务端可以发送完没有传达完毕的数据，传达完毕之后，服务端就会发送FIN释放连接。
  + 注意，在客户端收到服务端发送的FIN报文之后，不是直接进入CLOSE状态，而是需要等待一个时间段，这个时间段就是2MSL，主要的原因是为了让最后一个确认报文能够到达，如果B没有收到A发送来的确认报文的话，那么就会重新发送释放请求连接的报文，A等待了一段时间就是为了处理这种情况。还有就是为了让本次连接的持续时间内的所有的报文从网络里面消失，不要影响之后的TCP连接。

- TCP的流量控制
  + 流量控制的具体操作是接收端会通知发送端自己能接受的数据大小，于是发送端根据这个大小来调整自己发送的数据量。窗口越大吞吐量越高。
  + TCP的拥塞控制，TCP的拥塞控制的策略为慢启动，拥塞避免，快重传和快恢复。
  + TCP的粘包问题。TCP的粘包指的是发送端不断向接受端发送数据报文，两个数据包粘在一起的情况，一个数据包包括两个数据包的数据，这种问题被称为粘包问题。粘包的原因是TCP把数据看作是一连串的字节流，TCP的发送的数据小于TCP发送缓冲区的大小。
    + 发送端粘包，TCP将多次写入缓冲区的数据一次性发送，这种情况就有可能造成粘包问题。
    + 接收端粘包，接收端接收到数据之后，传输层的TCP协议会将接受的数据放到一个缓冲区里面，这个时候如果上层的应用层没有及时地从缓冲区里面取走数据，那么会出现取用数据报文的时候去用到两个数据报文的情况。
    + 总是就是接收端没有及时地取走缓冲区里面的数据，就会造成粘包问题。
  + 如何避免粘包问题？
    + 在每个包后面添加一个特殊的字符，用来区分不同的包。
    + 在报文首部添加一个包的长度。
- TCP建立连接的过程
  - 服务端：首先，创建一个socket，然后设置这个socket的属性，绑定对应的ip和端口。然后，我们开始监听这个端口，接受来自客户端的连接。收发数据，使用recv和send函数。最后就是关闭连接，关闭监听。
  - 客户端：首先，创建一个socket，然后设置相关的属性，绑定对应的ip地址和端口，设置连接对方的ip地址和端口。连接服务器，收发数据，关闭连接。
- UDP如何实现可靠传输
  - 首先，我们需要搞懂为什么UDP不可以实现可靠传输，但是TCP确可以呢？原因就是UDP允许丢失部分报文，没有重传的方案。为此，我们可以利用UDP来模拟TCP的可靠传输。实现的方式是参照tcp的可靠传输方式，只是不在传输层实现，而是在应用层进行实现。
    - 添加seq/ack机制，确保数据可以传输到对端。
    - 添加发送和接受缓冲区，主要是用于超时重传。
    - 添加超时重传机制。

### 应用层

- ARQ协议
  - ARQ协议是自动重传请求，如果发送方在一定的时间内没有收到回执，那么就会重新向接收端发送数据报文。
  - 停止等待ARQ协议
    - 发送端在发送的过程中，会先停止等待收到接收端发送过来的回执，如果没有收到，发送端会重新发送之前的报文分组。发送端会维护一个计时器，这个超时的时间一般会比传输的时间长。
  - 连续的ARQ协议
    - 停止等待ARQ协议对信道的占用不是连续的，而且由于需要等待接收端返回确认回执，所以对信道的资源利用率比较低。
    - 连续的ARQ协议是维护一个窗口，这个窗口有很多个分组，窗口的大小就是分组的个数，凡是窗口内的分组都可以直接发送出去而没有必要等待收到接收端的确认回执。对于按序列到达的最后一个分组，接收端会发送一个确认回执，如果发送端没有收到这个回执，那么这个分组后面的就会重新发送给接收端。这个一般在发送端都会有数据缓存，如果需要重新发送，那么就会取用缓存里面的重新发送。

+ HTTP断点续传

  + 使用的是HTTP1.0协议，通过在header的两个参数实现的，客户端的是Range，服务端的是Content-Range
  + Range，指定第一个字节的位置和最后一个字节的位置
  + Content-Range,返回当前的接受范围和文件的大小
  + 增强校验
    + 在实际场景中，可能进行断点续传的时候出现url的文档内容在服务器段已经发生了改变，此时，我们使用Last-Modified来标识文件的最后的修改时间，Last-Modified是服务器发送到客户端的HTTP头，Last-Modified-Since是客户端发送到服务端的请求头，发送请求的时候，客户端会先回将Last-Modified-Since发送到服务端，服务端进行校验是否是最新的，如果不是最新的，那么就会返回最新的内容

  + Etag，是为了解决Last-Modified不能解决的一些问题，有些文件是周期性改变的，但是内容没有改变，我们希望客户端不希望认为这些文件是改变了的。某些文件频繁修改，但是Last-Modified的感知是s级别的。这种修改是无法判断的。某些服务器不能得到精确的最后的修改时间。Etag比Last-Modified的作用是类似的，但是功能比它强。
  + if-Range,如果实体没有改变，那么返回剩下的部分，否则，重新发送整个实体。

  + 工作原理
    + 第一次请求，客户端发送一个HTTP GET请求，服务器处理请求，返回文件的内容以及相关的header，其中包括Etag
    + 第二次请求（断点续传），客户端发送一个http GET请求，同时发送If-Range
    + 服务端判断收到的Etag和计算Etag是否匹配。
  
+ HTTP 状态码

  + 1xx，指信息，表示请求已经接受，继续处理
  + 2xx，表示请求已经被成功接收，理解和接受
    + 200,OK,请求正常理解
    + 204,请求处理成功，但是没有资源返回
    + 206,对资源的某一部分的请求，关键字是Content-Range
  + 3xx，重定向，完成请求必须进行更近一步的操作
    + 301,永久重定向，请求的资源已经被永久迁移到新的url里面，今后任何新的请求都通过这个新的url进行访问。
    + 302,临时重定向，资源只是临时被移动，客户端可以继续请求原有的url
    + 304,缓存中读取，未修改，所请求的资源未修改，不返回任何资源，客户端通常会缓存访问过的资源
  + 4xx，客户端读错误，请求语法错误，或者请求无法实现
    + 400, 请求报文中语法错误
    + 401,请求未经过授权，需要有同感http认证的认证信息
    + 403,服务器收到请求，但是拒绝提供服务
    + 404,无法找到请求资源
    + 408,服务端等待的客户端发送的请求时间过程，超时。
  + 5xx，服务端错误，服务端未能实现合法的请求
    + 500, 服务器执行的时候发生错误
    + 501,服务器不支持的请求，无法完成请求
    + 503,服务器处于超负荷或者正在停机维护
  
+ http和https的区别
  + http以明文的方式发送数据。不提供任何的数据加密。容易被网站的攻击者截获数据。
  + https超文本安全传输协议。同样是使用http进行通信，但是将数据包通过TLS/SSL进行加密。是提供对网站服务器的身份认证，保护交换数据的隐私与完整性的一种协议。
  + 对称加密和非对称加密的区别
    + 对称加密就是指加密对象使用同一套密钥进行加密，优点就是预算速度快，但是向对方传输密钥是一个问题，可能存在被拦截的风险。
    + 非对称加密就是加密和解密有不同的密钥，一把是公钥，一把是私钥。利用公钥加密的信息只有利用私钥才可以解锁。私钥加密的报文只有公钥才可以解锁。这样在发送给对方报文的时候，只需要用对方发来的公钥进行加密就行了，接受的那一方只要用自己的私钥进行解密就行。优点就是解决了对称加密存在的缺陷。缺点就是运算速度慢。
  + 我们的https就是结合了对称加密和非对称加密的优点，通过使用非对称加密来传输密钥，然后使用对称加密来进行通信保证通信的效率。
  + 这里引入证书，证书是为了保证接受方确定公钥是来自服务端的而不是其他人冒充的。
  + 下面来介绍一下https的加密过程
    + 首先，建立一个连接，然后服务端知道客户端所使用的ssl的制定版本，加密算法和密钥的长度。
    + 然后，服务端想第三方数字认证机构发送自己的公钥，然后该机构利用自己的私钥进行加密同时附上数字签名。并且给服务器颁发证书。
    + 服务端将证书发送给客户端。
    + 客户端利用认证机构的公钥，对数字证书进行解密，然后得到里面的服务端的公钥。
    + 客户端使用服务端的公钥来加密自己的对称密钥，然后发送给服务端。
    + 服务端利用自己的私钥进行解密，然后就可以得到对称密钥了。
    + 最后，双方利用对称密钥进行通信。
  
+ 在浏览器输入一个url的执行过程
  + url解析。浏览器解析这个url，这个过程会检查缓存，如果有缓存，那么直接返回缓存的内容即可。首先，判断浏览器本地是否有缓存，先判断是否过期，如果有过期，那么重新向服务端申请，如果服务端没有更改资源，那么继续使用本地缓存，否则，重新返回资源并且缓存。如果没有缓存，那么向服务端进行申请并且缓存到本地浏览器即可。
  + DNS查询。查询的顺序依次是浏览器缓存->操作系统查询->路由器查询->ISP DNS查询->根域名DNS查询
  + TCP连接。应用层，传输层，网络层，链路层。
  + 服务器接受请求。
  + 浏览器接收数据。
  + 渲染界面。
  
+ GET请求和POST请求的区别

  + GET请求是幂等的，POST请求是非幂等的。

  + GET请求一般是获取数据，POST请求一般是用来提交数据。
  + GET请求的数据会把数据队列添加到通过提交的ACTION属性所指向的URL中，值和表单的内容一一对应。是可见的。POST请求将数据内容放到HTML header内传动到ACTION属性所只想的URL里面，是不可见的。
  + GET请求服务端一般是通过Request.QueryString方法获取参数，POST请求通过Request.Form方法获取参数
  + GET请求传输的数据量比较小，一般只有2kb，但是效率比较高。POST请求传输的数据量比较大，一般没有限制，传输大文件的时候只能用POST请求。

+ websocket的实现原理
  + 首先，我们需要知道为什么需要有websocket，因为http的连接是一个不能持久通信的数据传输协议，每次需要发送和接受数据的时候，就进行一个tcp连接。数据发送完成之后就会断开，对于我们即时通讯软件来说，显然是很低效的。
  + 所以，为了需要有持久通信的能力，websocket协议应运而生。
  + websocket是一种全双工通信。
  + websocket协议通过http协议来建立运输层之间的tcp连接，然后后续便和http没有关系了。
  
+ websocket协议的优点，消耗的资源很小，服务端和客户端都可以发送数据。缺点是少部分浏览器支持，各种浏览器支持的程度不同

+ session和cookie和token的区别
    - session是存储在服务器上的，当客户端向服务端请求创建一个sessionid的时候，服务端首先检查这个客户端的请求里面是否包含一个session标识的sessionid，如果包含，那么把这个sessionid对应的session检索处理，如果不包含，那么就创建一个新的键值对<session,session-id>,同时把这个sessionid返回给客户端。但是如果做了负载均衡，请求被转发到另一台服务器就会出现sessionid失效的情况。
    - 浏览器提供了三种保持session-id的方法：
      - cookie，将session保存在cookie里面。
      - url重写，把session-id放到请求的url里面。
      - 增加隐藏域，使用POST
  - cookie是在服务端生成的，然后发送给客户端，客户端在本地保存这些cookie，在下一次请求的时候将这个cookie发送给服务端。但是cookie容易被别人伪造。而且由于内容过大，会给网络造成压力。
  - token就是服务端给客户端发送一个token令牌，然后客户端在浏览器本地保存这个token，在之后的请求中，客户端都会携带这个token给服务端进行身份验证。为了防止有人伪造令牌，服务端会对token进行加密，同时添加签名和密钥。token是无状态的。为什么选择token？token是无状态，可扩展，可以支持移动设备，同时可以跨程序调用，可以进行加密，安全。有利于分布式部署。
  
+ 负载均衡

  + 部署多台服务器的时候，就需要我们将请求分发到不同的服务器上来提高服务的可靠性。这里主要介绍一些负载均衡算法
    + 随机算法：按照权重设置随机概率，在一个截面上碰撞的概率高，但是调用量越大分布越均匀。
    + 论询和加权轮询，轮询是按照公约后的权重设置轮询比率的。加权轮询就是为在轮询中的每台服务器附加一定的权重的算法。
    + 最小连接和加权最小连接，和链接数最少的服务器进行连接的服务器进行通信的算法。
    + 哈希算法，一致性哈希，先通过哈希算法，将哈希值一样的请求打到同一个服务器上面去。如果这个服务器挂了，那么就平摊到其他的服务器上。
    + IP地址散列。通过管理发送放ip和接受方的ip，将来自同一个发送方的分组统一转发到相同的服务器上。
    + URL散列，将同一个url发送的请求分发到同一个服务器上。

+ 常见的http请求方法

  + GET，获取资源
  + POST，传输实体
  + PUT，上传文件
  + DELETE，删除文件
  + HEAD，获取报文头部，不返回报文主体
  + PATCH，对资源进行部分修改
  + OPTIONAL，查询支持的方法
  + CONNECT，要求用隧道协议来代理
  + TRACE，服务器将通信的路径返回给客户端。

+ http1.0http1.1和http2.0的区别

  + http1.0支持长连接，在一个连接里面可以执行多次请求，支持缓存处理，错误状态码，HOST域以及宽带优化以及网络连接的使用
  + http2.0支持二进制数据流，同时头部压缩，以及多路复用一个连接多个request，根据requestid进行区分不同的请求。服务端的推送。

